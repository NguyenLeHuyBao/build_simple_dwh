[2022-12-07T16:16:24.247+0000] {taskinstance.py:1165} INFO - ðŸ¤ª Dependencies all met for <TaskInstance: get_raw_data_from_sources.get_raw_data_from_postgres_sources scheduled__2022-12-05T19:00:00+00:00 [queued]>
[2022-12-07T16:16:24.254+0000] {taskinstance.py:1165} INFO - ðŸ¤ª Dependencies all met for <TaskInstance: get_raw_data_from_sources.get_raw_data_from_postgres_sources scheduled__2022-12-05T19:00:00+00:00 [queued]>
[2022-12-07T16:16:24.255+0000] {taskinstance.py:1362} INFO - ðŸ¤ª 
--------------------------------------------------------------------------------
[2022-12-07T16:16:24.256+0000] {taskinstance.py:1363} INFO - ðŸ¤ª Starting attempt 6 of 9
[2022-12-07T16:16:24.256+0000] {taskinstance.py:1364} INFO - ðŸ¤ª 
--------------------------------------------------------------------------------
[2022-12-07T16:16:24.270+0000] {taskinstance.py:1383} INFO - ðŸ¤ª Executing <Task(PythonOperator): get_raw_data_from_postgres_sources> on 2022-12-05 19:00:00+00:00
[2022-12-07T16:16:24.273+0000] {standard_task_runner.py:55} INFO - ðŸ¤ª Started process 180 to run task
[2022-12-07T16:16:24.278+0000] {standard_task_runner.py:82} INFO - ðŸ¤ª Running: ['airflow', 'tasks', 'run', 'get_raw_data_from_sources', 'get_raw_data_from_postgres_sources', 'scheduled__2022-12-05T19:00:00+00:00', '--job-id', '11', '--raw', '--subdir', 'DAGS_FOLDER/ingest_dwh_daily.py', '--cfg-path', '/tmp/tmplkzb6p9n']
[2022-12-07T16:16:24.280+0000] {standard_task_runner.py:83} INFO - ðŸ¤ª Job 11: Subtask get_raw_data_from_postgres_sources
[2022-12-07T16:16:24.331+0000] {task_command.py:376} INFO - ðŸ¤ª Running <TaskInstance: get_raw_data_from_sources.get_raw_data_from_postgres_sources scheduled__2022-12-05T19:00:00+00:00 [running]> on host db3df0a6f633
[2022-12-07T16:16:24.380+0000] {taskinstance.py:1590} INFO - ðŸ¤ª Exporting the following env vars:
AIRFLOW_CTX_DAG_EMAIL=gp.data@galaxy.com.vn
AIRFLOW_CTX_DAG_OWNER=data_team
AIRFLOW_CTX_DAG_ID=get_raw_data_from_sources
AIRFLOW_CTX_TASK_ID=get_raw_data_from_postgres_sources
AIRFLOW_CTX_EXECUTION_DATE=2022-12-05T19:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=6
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-12-05T19:00:00+00:00
[2022-12-07T16:16:24.393+0000] {logging_mixin.py:137} INFO - ðŸ¤ª Start getting data from source Postgres - Table: users
[2022-12-07T16:16:24.394+0000] {logging_mixin.py:137} INFO - ðŸ¤ª <db_handler.postgres_handler.PostgresHandler object at 0x7f90a4ae78e0> SELECT user_id, name, email, mobile FROM public.users user_id, name, email, mobile
[2022-12-07T16:16:24.400+0000] {taskinstance.py:1851} ERROR - ðŸ¤ª Task failed with exception
Traceback (most recent call last):
  File "/opt/bitnami/python/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 969, in _finalize_columns_and_data
    columns = _validate_or_indexify_columns(contents, columns)
  File "/opt/bitnami/python/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 1017, in _validate_or_indexify_columns
    raise AssertionError(
AssertionError: 1 columns passed, passed data had 4 columns

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/bitnami/python/lib/python3.8/site-packages/airflow/operators/python.py", line 175, in execute
    return_value = self.execute_callable()
  File "/opt/bitnami/python/lib/python3.8/site-packages/airflow/operators/python.py", line 193, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/airflow/dags/processing/ingest_psql_source.py", line 57, in ingest_psql_source
    data = extract_data_from_source(postgres_handler=postgres_handler,
  File "/airflow/dags/processing/ingest_psql_source.py", line 12, in extract_data_from_source
    df = pd.DataFrame(data, columns=[list_columns])
  File "/opt/bitnami/python/lib/python3.8/site-packages/pandas/core/frame.py", line 745, in __init__
    arrays, columns, index = nested_data_to_arrays(
  File "/opt/bitnami/python/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 510, in nested_data_to_arrays
    arrays, columns = to_arrays(data, columns, dtype=dtype)
  File "/opt/bitnami/python/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 875, in to_arrays
    content, columns = _finalize_columns_and_data(arr, columns, dtype)
  File "/opt/bitnami/python/lib/python3.8/site-packages/pandas/core/internals/construction.py", line 972, in _finalize_columns_and_data
    raise ValueError(err) from err
ValueError: 1 columns passed, passed data had 4 columns
[2022-12-07T16:16:24.408+0000] {taskinstance.py:1401} INFO - ðŸ¤ª Marking task as UP_FOR_RETRY. dag_id=get_raw_data_from_sources, task_id=get_raw_data_from_postgres_sources, execution_date=20221205T190000, start_date=20221207T161624, end_date=20221207T161624
[2022-12-07T16:16:24.420+0000] {standard_task_runner.py:100} ERROR - ðŸ¤ª Failed to execute job 11 for task get_raw_data_from_postgres_sources (1 columns passed, passed data had 4 columns; 180)
[2022-12-07T16:16:24.450+0000] {local_task_job.py:159} INFO - ðŸ¤ª Task exited with return code 1
[2022-12-07T16:16:24.464+0000] {taskinstance.py:2623} INFO - ðŸ¤ª 0 downstream tasks scheduled from follow-on schedule check
